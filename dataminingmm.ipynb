{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathon15 = pd.read_csv('marathon_results_2015.csv')\n",
    "marathon16 = pd.read_csv('marathon_results_2016.csv')\n",
    "marathon17 = pd.read_csv('marathon_results_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Bib</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>M/F</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>35K</th>\n",
       "      <th>40K</th>\n",
       "      <th>Pace</th>\n",
       "      <th>Proj Time</th>\n",
       "      <th>Official Time</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Division</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Desisa, Lelisa</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>Ambo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ETH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:02:39</td>\n",
       "      <td>0:04:56</td>\n",
       "      <td>-</td>\n",
       "      <td>2:09:17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Tsegay, Yemane Adhane</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ETH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:02:42</td>\n",
       "      <td>0:04:58</td>\n",
       "      <td>-</td>\n",
       "      <td>2:09:48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Chebet, Wilson</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>Marakwet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:03:01</td>\n",
       "      <td>0:04:59</td>\n",
       "      <td>-</td>\n",
       "      <td>2:10:22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Kipyego, Bernard</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:48:03</td>\n",
       "      <td>2:03:47</td>\n",
       "      <td>0:05:00</td>\n",
       "      <td>-</td>\n",
       "      <td>2:10:47</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Korir, Wesley</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>Kitale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:03:27</td>\n",
       "      <td>0:05:00</td>\n",
       "      <td>-</td>\n",
       "      <td>2:10:49</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Bib                   Name  Age M/F         City State Country  \\\n",
       "0         0.0   3         Desisa, Lelisa   25   M         Ambo   NaN     ETH   \n",
       "1         1.0   4  Tsegay, Yemane Adhane   30   M  Addis Ababa   NaN     ETH   \n",
       "2         2.0   8         Chebet, Wilson   29   M     Marakwet   NaN     KEN   \n",
       "3         3.0  11       Kipyego, Bernard   28   M      Eldoret   NaN     KEN   \n",
       "4         4.0  10          Korir, Wesley   32   M       Kitale   NaN     KEN   \n",
       "\n",
       "  Citizen Unnamed: 9  ...      35K      40K     Pace Proj Time Official Time  \\\n",
       "0     NaN        NaN  ...  1:47:59  2:02:39  0:04:56         -       2:09:17   \n",
       "1     NaN        NaN  ...  1:47:59  2:02:42  0:04:58         -       2:09:48   \n",
       "2     NaN        NaN  ...  1:47:59  2:03:01  0:04:59         -       2:10:22   \n",
       "3     NaN        NaN  ...  1:48:03  2:03:47  0:05:00         -       2:10:47   \n",
       "4     NaN        NaN  ...  1:47:59  2:03:27  0:05:00         -       2:10:49   \n",
       "\n",
       "  Overall Gender Division  Year Unnamed: 8  \n",
       "0       1      1        1  2015        NaN  \n",
       "1       2      2        2  2015        NaN  \n",
       "2       3      3        3  2015        NaN  \n",
       "3       4      4        4  2015        NaN  \n",
       "4       5      5        5  2015        NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marathon15['Year'] = 2015\n",
    "marathon16['Year'] = 2016\n",
    "marathon17['Year'] = 2017\n",
    "\n",
    "# Combine the dataframes\n",
    "df_combined = pd.concat([marathon15, marathon16, marathon17], ignore_index=True)\n",
    "\n",
    "# Now df_combined is your combined dataframe with the 'Year' column\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>M/F</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>5K</th>\n",
       "      <th>10K</th>\n",
       "      <th>15K</th>\n",
       "      <th>20K</th>\n",
       "      <th>Half</th>\n",
       "      <th>25K</th>\n",
       "      <th>30K</th>\n",
       "      <th>35K</th>\n",
       "      <th>40K</th>\n",
       "      <th>Pace</th>\n",
       "      <th>Official Time</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Division</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desisa, Lelisa</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>Ambo</td>\n",
       "      <td>ETH</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:43</td>\n",
       "      <td>0:44:57</td>\n",
       "      <td>1:00:29</td>\n",
       "      <td>1:04:02</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:02:39</td>\n",
       "      <td>0:04:56</td>\n",
       "      <td>2:09:17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tsegay, Yemane Adhane</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>ETH</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:43</td>\n",
       "      <td>0:44:58</td>\n",
       "      <td>1:00:28</td>\n",
       "      <td>1:04:01</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:31:59</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:02:42</td>\n",
       "      <td>0:04:58</td>\n",
       "      <td>2:09:48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chebet, Wilson</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>Marakwet</td>\n",
       "      <td>KEN</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:43</td>\n",
       "      <td>0:44:57</td>\n",
       "      <td>1:00:29</td>\n",
       "      <td>1:04:02</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:03:01</td>\n",
       "      <td>0:04:59</td>\n",
       "      <td>2:10:22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kipyego, Bernard</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>KEN</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:44</td>\n",
       "      <td>0:45:01</td>\n",
       "      <td>1:00:29</td>\n",
       "      <td>1:04:02</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:48:03</td>\n",
       "      <td>2:03:47</td>\n",
       "      <td>0:05:00</td>\n",
       "      <td>2:10:47</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Korir, Wesley</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>Kitale</td>\n",
       "      <td>KEN</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:44</td>\n",
       "      <td>0:44:58</td>\n",
       "      <td>1:00:28</td>\n",
       "      <td>1:04:01</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:03:27</td>\n",
       "      <td>0:05:00</td>\n",
       "      <td>2:10:49</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79633</th>\n",
       "      <td>Steinbach, Paula Eyvonne</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>USA</td>\n",
       "      <td>0:46:44</td>\n",
       "      <td>1:35:41</td>\n",
       "      <td>2:23:35</td>\n",
       "      <td>3:12:44</td>\n",
       "      <td>3:23:31</td>\n",
       "      <td>4:12:06</td>\n",
       "      <td>5:03:08</td>\n",
       "      <td>5:55:18</td>\n",
       "      <td>6:46:57</td>\n",
       "      <td>0:16:24</td>\n",
       "      <td>7:09:39</td>\n",
       "      <td>26407</td>\n",
       "      <td>11972</td>\n",
       "      <td>344</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79634</th>\n",
       "      <td>Avelino, Andrew R.</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>Fayetteville</td>\n",
       "      <td>USA</td>\n",
       "      <td>0:32:03</td>\n",
       "      <td>1:05:33</td>\n",
       "      <td>1:52:17</td>\n",
       "      <td>2:49:41</td>\n",
       "      <td>3:00:26</td>\n",
       "      <td>3:50:19</td>\n",
       "      <td>4:50:01</td>\n",
       "      <td>5:53:48</td>\n",
       "      <td>6:54:21</td>\n",
       "      <td>0:16:40</td>\n",
       "      <td>7:16:59</td>\n",
       "      <td>26408</td>\n",
       "      <td>14436</td>\n",
       "      <td>4774</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79635</th>\n",
       "      <td>Hantel, Johanna</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>Malvern</td>\n",
       "      <td>USA</td>\n",
       "      <td>0:53:11</td>\n",
       "      <td>1:43:36</td>\n",
       "      <td>2:32:36</td>\n",
       "      <td>-</td>\n",
       "      <td>3:36:24</td>\n",
       "      <td>4:15:21</td>\n",
       "      <td>5:06:37</td>\n",
       "      <td>6:00:33</td>\n",
       "      <td>6:54:38</td>\n",
       "      <td>0:16:47</td>\n",
       "      <td>7:19:37</td>\n",
       "      <td>26409</td>\n",
       "      <td>11973</td>\n",
       "      <td>698</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79636</th>\n",
       "      <td>Reilly, Bill</td>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>New York</td>\n",
       "      <td>USA</td>\n",
       "      <td>0:40:34</td>\n",
       "      <td>1:27:19</td>\n",
       "      <td>2:17:17</td>\n",
       "      <td>3:11:40</td>\n",
       "      <td>3:22:30</td>\n",
       "      <td>4:06:10</td>\n",
       "      <td>5:07:09</td>\n",
       "      <td>6:06:07</td>\n",
       "      <td>6:56:08</td>\n",
       "      <td>0:16:49</td>\n",
       "      <td>7:20:44</td>\n",
       "      <td>26410</td>\n",
       "      <td>14437</td>\n",
       "      <td>1043</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79637</th>\n",
       "      <td>Rigsby, Scott</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>USA</td>\n",
       "      <td>0:39:36</td>\n",
       "      <td>1:17:12</td>\n",
       "      <td>2:00:10</td>\n",
       "      <td>2:58:55</td>\n",
       "      <td>3:08:16</td>\n",
       "      <td>4:27:14</td>\n",
       "      <td>5:37:13</td>\n",
       "      <td>6:39:07</td>\n",
       "      <td>7:41:23</td>\n",
       "      <td>0:18:15</td>\n",
       "      <td>7:58:14</td>\n",
       "      <td>26411</td>\n",
       "      <td>14438</td>\n",
       "      <td>2553</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79638 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name  Age M/F          City Country       5K  \\\n",
       "0                Desisa, Lelisa   25   M          Ambo     ETH  0:14:43   \n",
       "1         Tsegay, Yemane Adhane   30   M   Addis Ababa     ETH  0:14:43   \n",
       "2                Chebet, Wilson   29   M      Marakwet     KEN  0:14:43   \n",
       "3              Kipyego, Bernard   28   M       Eldoret     KEN  0:14:43   \n",
       "4                 Korir, Wesley   32   M        Kitale     KEN  0:14:43   \n",
       "...                         ...  ...  ..           ...     ...      ...   \n",
       "79633  Steinbach, Paula Eyvonne   61   F       Ontario     USA  0:46:44   \n",
       "79634        Avelino, Andrew R.   25   M  Fayetteville     USA  0:32:03   \n",
       "79635           Hantel, Johanna   57   F       Malvern     USA  0:53:11   \n",
       "79636              Reilly, Bill   64   M      New York     USA  0:40:34   \n",
       "79637             Rigsby, Scott   48   M    Alpharetta     USA  0:39:36   \n",
       "\n",
       "           10K      15K      20K     Half      25K      30K      35K      40K  \\\n",
       "0      0:29:43  0:44:57  1:00:29  1:04:02  1:16:07  1:32:00  1:47:59  2:02:39   \n",
       "1      0:29:43  0:44:58  1:00:28  1:04:01  1:16:07  1:31:59  1:47:59  2:02:42   \n",
       "2      0:29:43  0:44:57  1:00:29  1:04:02  1:16:07  1:32:00  1:47:59  2:03:01   \n",
       "3      0:29:44  0:45:01  1:00:29  1:04:02  1:16:07  1:32:00  1:48:03  2:03:47   \n",
       "4      0:29:44  0:44:58  1:00:28  1:04:01  1:16:07  1:32:00  1:47:59  2:03:27   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "79633  1:35:41  2:23:35  3:12:44  3:23:31  4:12:06  5:03:08  5:55:18  6:46:57   \n",
       "79634  1:05:33  1:52:17  2:49:41  3:00:26  3:50:19  4:50:01  5:53:48  6:54:21   \n",
       "79635  1:43:36  2:32:36        -  3:36:24  4:15:21  5:06:37  6:00:33  6:54:38   \n",
       "79636  1:27:19  2:17:17  3:11:40  3:22:30  4:06:10  5:07:09  6:06:07  6:56:08   \n",
       "79637  1:17:12  2:00:10  2:58:55  3:08:16  4:27:14  5:37:13  6:39:07  7:41:23   \n",
       "\n",
       "          Pace Official Time  Overall  Gender  Division  Year  \n",
       "0      0:04:56       2:09:17        1       1         1  2015  \n",
       "1      0:04:58       2:09:48        2       2         2  2015  \n",
       "2      0:04:59       2:10:22        3       3         3  2015  \n",
       "3      0:05:00       2:10:47        4       4         4  2015  \n",
       "4      0:05:00       2:10:49        5       5         5  2015  \n",
       "...        ...           ...      ...     ...       ...   ...  \n",
       "79633  0:16:24       7:09:39    26407   11972       344  2017  \n",
       "79634  0:16:40       7:16:59    26408   14436      4774  2017  \n",
       "79635  0:16:47       7:19:37    26409   11973       698  2017  \n",
       "79636  0:16:49       7:20:44    26410   14437      1043  2017  \n",
       "79637  0:18:15       7:58:14    26411   14438      2553  2017  \n",
       "\n",
       "[79638 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to be dropped\n",
    "columns_to_drop = ['Unnamed: 0', 'State', 'Citizen', 'Unnamed: 9', 'Proj Time', 'Bib', 'Unnamed: 8']\n",
    "\n",
    "# Drop the specified columns from the dataframe\n",
    "df = df_combined.drop(columns=columns_to_drop, errors='ignore')  # errors='ignore' to avoid error if a column is not present\n",
    "\n",
    "# Display the first 5 rows to confirm the columns are dropped\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1027124.8881184158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your cleaned dataframe and 'Official Time' and '10K' are the columns of interest.\n",
    "\n",
    "# Convert '10K' and 'Official Time' to total seconds for the model.\n",
    "def time_to_seconds(time_str):\n",
    "    # Function to convert time string to seconds.\n",
    "    try:\n",
    "        h, m, s = time_str.split(':')\n",
    "        return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "    except ValueError: # if conversion fails, return NaN\n",
    "        return np.nan\n",
    "\n",
    "df['10K_seconds'] = df['10K'].apply(time_to_seconds)\n",
    "df['Official_Time_seconds'] = df['Official Time'].apply(time_to_seconds)\n",
    "\n",
    "# Drop rows with NaN values that resulted from conversion errors\n",
    "df = df.dropna(subset=['10K_seconds', 'Official_Time_seconds'])\n",
    "\n",
    "# Define your feature and target variables\n",
    "X = df[['10K_seconds']]  # Features\n",
    "y = df['Official_Time_seconds']  # Target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the performance metric\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1027124.8881184158\n",
      "Mean Absolute Error: 738.036675796353\n",
      "R-squared Score: 0.8357552274303383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40545/273308447.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Gender'] = df['M/F'].map({'M': 1, 'F': 0})  # Assuming M/F are the only two genders in the dataset\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Convert 'Age' and 'M/F' to numerical values for the model\n",
    "df['Gender'] = df['M/F'].map({'M': 1, 'F': 0})  # Assuming M/F are the only two genders in the dataset\n",
    "\n",
    "# Now define your features with 'Age' and 'Gender'\n",
    "X = df[['10K_seconds', 'Age', 'Gender']]  # Features\n",
    "\n",
    "# Continue with the same steps as before for splitting the data\n",
    "# Initialize and train the multiple regression model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error, mean absolute error, and R-squared score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 521207.3630973528\n",
      "Mean Absolute Error: 473.05386345166096\n",
      "R-squared Score: 0.915532329936932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40545/3744228773.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'Half_seconds'] = df['Half'].apply(time_to_seconds)\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Half' to total seconds for the model\n",
    "# Instead of directly setting df['Half_seconds'], use the .loc method\n",
    "df.loc[:, 'Half_seconds'] = df['Half'].apply(time_to_seconds)\n",
    "\n",
    "# Drop rows with NaN values that resulted from conversion errors\n",
    "# Drop rows with NaN values that resulted from conversion errors\n",
    "df = df.dropna(subset=['10K_seconds', 'Half_seconds', 'Official_Time_seconds'])\n",
    "\n",
    "# Define your feature and target variables\n",
    "# Now including 'Half_seconds' as a predictor\n",
    "X = df[['10K_seconds', 'Age', 'Gender', 'Half_seconds']]  # Features\n",
    "y = df['Official_Time_seconds']  # Target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the multiple regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error, mean absolute error, and R-squared score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 521207.3630973528\n",
      "Mean Absolute Error: 473.05386345166096\n",
      "R-squared Score: 0.915532329936932\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your cleaned dataframe and 'Half' is the column with the half marathon times.\n",
    "\n",
    "# Convert 'Half' to total seconds for the model, using the same function as before.\n",
    "df['Half_seconds'] = df['Half'].apply(time_to_seconds)\n",
    "\n",
    "# Drop rows with NaN values that resulted from conversion errors\n",
    "df = df.dropna(subset=['Half_seconds'])\n",
    "\n",
    "# Now define your features with '10K_seconds', 'Age', 'Gender', and 'Half_seconds'\n",
    "X = df[['10K_seconds', 'Age', 'Gender', 'Half_seconds']]  # Features\n",
    "\n",
    "# Split the data into training and testing sets as before\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the multiple regression model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using the previous metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the updated performance metrics\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for KNN: 567183.7121066868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you've already prepared your DataFrame `df` and selected features and target\n",
    "X = df[['10K_seconds', 'Age', 'Gender', 'Half_seconds']]  # Features\n",
    "y = df['Official_Time_seconds']  # Target\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize KNN with a specific number of neighbors, e.g., 5\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error for KNN: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading keras-3.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.7 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-3.1.1 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 optree-0.10.0 protobuf-4.25.3 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 werkzeug-3.0.1 wheel-0.43.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 14:31:32.181732: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-25 14:31:32.470896: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-25 14:31:32.686042: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 14:31:34.799470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 148566112.0000 - val_loss: 6601169.5000\n",
      "Epoch 2/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 4464449.5000 - val_loss: 1398077.6250\n",
      "Epoch 3/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1123593.3750 - val_loss: 661768.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 622461.5625 - val_loss: 513496.4375\n",
      "Epoch 5/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 516289.5312 - val_loss: 465897.5312\n",
      "Epoch 6/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 503537.5938 - val_loss: 458269.7500\n",
      "Epoch 7/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 490561.7500 - val_loss: 450868.7188\n",
      "Epoch 8/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 496815.0938 - val_loss: 452479.7188\n",
      "Epoch 9/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 477453.6562 - val_loss: 448387.3438\n",
      "Epoch 10/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 496297.4062 - val_loss: 447627.5312\n",
      "Epoch 11/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 492953.5000 - val_loss: 448850.4062\n",
      "Epoch 12/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 484743.8125 - val_loss: 465329.6562\n",
      "Epoch 13/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 498459.3750 - val_loss: 446547.0938\n",
      "Epoch 14/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 479278.5938 - val_loss: 448942.3438\n",
      "Epoch 15/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 999us/step - loss: 488929.4062 - val_loss: 447856.4688\n",
      "Epoch 16/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 475571.2812 - val_loss: 455411.2812\n",
      "Epoch 17/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 479972.0312 - val_loss: 448752.5625\n",
      "Epoch 18/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 496707.8438 - val_loss: 448602.9688\n",
      "Epoch 19/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 478480.0938 - val_loss: 448238.1250\n",
      "Epoch 20/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 478545.4062 - val_loss: 446473.7188\n",
      "Epoch 21/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 990us/step - loss: 463450.4062 - val_loss: 447091.7500\n",
      "Epoch 22/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 475772.6562 - val_loss: 448056.4062\n",
      "Epoch 23/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 463328.6562 - val_loss: 446475.9062\n",
      "Epoch 24/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 486116.4375 - val_loss: 447440.7500\n",
      "Epoch 25/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 490352.5000 - val_loss: 448443.9688\n",
      "Epoch 26/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 500749.2188 - val_loss: 445940.4375\n",
      "Epoch 27/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 486874.9375 - val_loss: 447147.7500\n",
      "Epoch 28/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 479004.0312 - val_loss: 446279.4688\n",
      "Epoch 29/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 480615.2500 - val_loss: 445644.5000\n",
      "Epoch 30/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 482957.2188 - val_loss: 449108.4375\n",
      "Epoch 31/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 481157.3750 - val_loss: 449650.7188\n",
      "Epoch 32/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 497157.1562 - val_loss: 445372.3750\n",
      "Epoch 33/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 478775.9375 - val_loss: 446652.9062\n",
      "Epoch 34/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 479492.1875 - val_loss: 446589.9062\n",
      "Epoch 35/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 998us/step - loss: 490146.1875 - val_loss: 448362.3438\n",
      "Epoch 36/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 520048.2500 - val_loss: 446363.9688\n",
      "Epoch 37/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 471343.0000 - val_loss: 446167.6875\n",
      "Epoch 38/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955us/step - loss: 466212.6250 - val_loss: 445901.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 500718.6562 - val_loss: 449943.3438\n",
      "Epoch 40/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963us/step - loss: 484575.0625 - val_loss: 445112.9688\n",
      "Epoch 41/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 469046.4688 - val_loss: 447185.3125\n",
      "Epoch 42/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step - loss: 485387.4375 - val_loss: 447623.4062\n",
      "Epoch 43/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 481433.0000 - val_loss: 445806.7500\n",
      "Epoch 44/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 484867.7188 - val_loss: 445078.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 999us/step - loss: 477608.8750 - val_loss: 447439.6250\n",
      "Epoch 46/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 492855.4375 - val_loss: 448381.0625\n",
      "Epoch 47/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 990us/step - loss: 496729.8750 - val_loss: 445809.9688\n",
      "Epoch 48/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 478503.1250 - val_loss: 445778.1562\n",
      "Epoch 49/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 481826.6562 - val_loss: 445696.0312\n",
      "Epoch 50/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 481160.6562 - val_loss: 445519.3438\n",
      "Epoch 51/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 478651.5312 - val_loss: 448210.0625\n",
      "Epoch 52/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 954us/step - loss: 484393.8125 - val_loss: 446966.5625\n",
      "Epoch 53/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 992us/step - loss: 480615.8750 - val_loss: 445239.5312\n",
      "Epoch 54/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 487771.4062 - val_loss: 449119.5625\n",
      "Epoch 55/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 481718.4375 - val_loss: 448597.3125\n",
      "Epoch 56/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step - loss: 471873.9688 - val_loss: 448430.3125\n",
      "Epoch 57/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 985us/step - loss: 486930.5000 - val_loss: 446400.3125\n",
      "Epoch 58/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 484569.2812 - val_loss: 454513.5938\n",
      "Epoch 59/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step - loss: 475880.9062 - val_loss: 448384.8125\n",
      "Epoch 60/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 502286.5625 - val_loss: 445548.3750\n",
      "Epoch 61/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 497882.8438 - val_loss: 443986.2500\n",
      "Epoch 62/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 483037.5938 - val_loss: 454203.9688\n",
      "Epoch 63/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 466554.9688 - val_loss: 445757.3125\n",
      "Epoch 64/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 477534.4062 - val_loss: 447152.2500\n",
      "Epoch 65/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 935us/step - loss: 470674.4375 - val_loss: 445151.4688\n",
      "Epoch 66/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 482997.4062 - val_loss: 446503.4062\n",
      "Epoch 67/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - loss: 476473.4688 - val_loss: 445374.3125\n",
      "Epoch 68/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 477609.8750 - val_loss: 448710.1562\n",
      "Epoch 69/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 941us/step - loss: 478666.0625 - val_loss: 449170.6875\n",
      "Epoch 70/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 485894.1250 - val_loss: 445409.0938\n",
      "Epoch 71/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step - loss: 472610.2188 - val_loss: 449695.6250\n",
      "Epoch 72/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 473708.3125 - val_loss: 446036.2188\n",
      "Epoch 73/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 466763.0625 - val_loss: 445136.0938\n",
      "Epoch 74/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 495994.1250 - val_loss: 452625.7188\n",
      "Epoch 75/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 980us/step - loss: 469645.5000 - val_loss: 448037.1875\n",
      "Epoch 76/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 494191.8750 - val_loss: 444942.0625\n",
      "Epoch 77/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 474145.6562 - val_loss: 446030.1875\n",
      "Epoch 78/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 970us/step - loss: 464881.0625 - val_loss: 445980.1875\n",
      "Epoch 79/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 488868.2188 - val_loss: 445619.9688\n",
      "Epoch 80/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 474419.3750 - val_loss: 445558.4688\n",
      "Epoch 81/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 994us/step - loss: 497318.9375 - val_loss: 449060.9062\n",
      "Epoch 82/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 485693.1562 - val_loss: 444864.0938\n",
      "Epoch 83/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 469217.3125 - val_loss: 445688.6562\n",
      "Epoch 84/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 993us/step - loss: 468081.3125 - val_loss: 444759.1250\n",
      "Epoch 85/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 480733.2500 - val_loss: 454700.5312\n",
      "Epoch 86/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 481654.8125 - val_loss: 447246.8750\n",
      "Epoch 87/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 501589.3750 - val_loss: 444647.0625\n",
      "Epoch 88/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 982us/step - loss: 484670.3438 - val_loss: 447488.1875\n",
      "Epoch 89/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 486751.9688 - val_loss: 445045.8750\n",
      "Epoch 90/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 496598.2500 - val_loss: 450427.4062\n",
      "Epoch 91/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 496350.0938 - val_loss: 446400.4688\n",
      "Epoch 92/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 475379.2812 - val_loss: 446431.6250\n",
      "Epoch 93/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 473389.1562 - val_loss: 445763.9688\n",
      "Epoch 94/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 474844.0000 - val_loss: 445109.9375\n",
      "Epoch 95/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 494377.7812 - val_loss: 445171.5000\n",
      "Epoch 96/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 465594.7500 - val_loss: 448155.8125\n",
      "Epoch 97/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 992us/step - loss: 469211.9375 - val_loss: 446457.2500\n",
      "Epoch 98/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 477509.8438 - val_loss: 449234.5312\n",
      "Epoch 99/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 471279.1250 - val_loss: 451776.8750\n",
      "Epoch 100/100\n",
      "\u001b[1m1590/1590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 493186.6250 - val_loss: 446798.0000\n",
      "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 513093.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "523142.71875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
